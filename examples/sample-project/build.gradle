import java.nio.file.Files
import java.util.zip.ZipEntry
import java.util.zip.ZipOutputStream
import org.apache.commons.io.FilenameUtils
import com.google.gson.JsonParser
import com.google.gson.stream.JsonReader

buildscript {
  repositories {
    jcenter()
  }
  dependencies {
    classpath "com.marklogic:marklogic-geo-data-services-modules:1.1.0"
    classpath "com.google.code.gson:gson:2.8.6"
  }
}

plugins {
  id "net.saliman.properties" version "1.5.1"
  id "com.marklogic.ml-gradle" version "3.15.2"
}

repositories {
  jcenter()

  // Needed for some mlcp dependencies, such as commons-csv:1.5.1-marklogic
  maven { url "http://developer.marklogic.com/maven2/" }
}

configurations {
  mlcp
}

dependencies {
  mlBundle "com.marklogic:marklogic-geo-data-services-modules:1.1.0"
  mlcp "com.marklogic:mlcp:9.0.9"

  /**
    * mlcp uses Log4j for logging, and if Log4j can't find a configuration file, it will complain and you'll
    * get none of mlcp's usually-useful logging. It is recommended then that your Gradle configuration for
    * mlcp include a directory or some other resource that provides a log4j.properties file.
    */
  mlcp files("lib")
}

// We are not using the ml-data capability of ml-gradle because we are loading from zip files.
// Prior to running this command, please execute `gradle mlDeploy`.
task loadExampleData(dependsOn: [
  "loadGDeltExampleData",
  "loadZipCodeBoundaryExampleData"
])

task loadGDeltExampleData(type: com.marklogic.gradle.task.MlcpTask) {
  classpath = configurations.mlcp
  command = "IMPORT"
  port = mlAppConfig.restPort
  database = mlAppConfig.contentDatabaseName
  input_file_path = "data/gkg_geojson"
  input_compressed = "true"
  output_collections = "example-gkg,test-data"
  output_permissions = "rest-reader,read,rest-writer,update,geo-data-services-reader,read,geo-data-services-writer,update"
  output_uri_replace = ".*/data/,'/'"
}

task loadZipCodeBoundaryExampleData(type: com.marklogic.gradle.task.MlcpTask) {
  classpath = configurations.mlcp
  command = "IMPORT"
  port = mlAppConfig.restPort
  database = mlAppConfig.contentDatabaseName
  input_file_path = "data/zipcodes"
  input_compressed = "true"
  output_collections = "zipcodes,test-data"
  output_permissions = "rest-reader,read,rest-writer,update,geo-data-services-reader,read,geo-data-services-writer,update"
  output_uri_replace = ".*/data/,'/'"
}

// tasks to automate downloading of sample data
task downloadExampleData(dependsOn: [
  "downloadGDeltExampleData",
  "downloadZipCodeBoundaryExampleData"
])

task cleanExampleData(type: Delete) {
  def dirs = ["data/gkg_geojson", "data/zipcodes"]
  doFirst {
    dirs.each { println "Deleting ${it}..." }
  }
  delete dirs
}

task downloadGDeltExampleData(type: Exec) {
  def startObjectID = 6000
  def url = "http://api.gdeltproject.org/api/v1/gkg_geojson?TIMESPAN=1440&MAXROWS=250000&OUTPUTFIELDS=name,geores,url,domain,sharingimage,lang,themes,names,tone,wordcount,numcounts,urlpubtimedate"

  doFirst {
    println "Making a request to " + url
  }

  commandLine "curl", "-s", url
  standardOutput = new ByteArrayOutputStream()
  
  def out = {
    return standardOutput
  }
  
  doLast {
    def id = startObjectID
    def parser = new JsonParser()
    def responseElem = parser.parse(out().toString())
    assert responseElem.isJsonObject()
    def response = responseElem.getAsJsonObject()
    def features = response.getAsJsonArray("features")

    def tempFile = File.createTempFile("gkg_geojson_", ".zip")
    def fs = new FileOutputStream(tempFile)
    def zs = new ZipOutputStream(fs)

    for (featureElem in features) {
      def feature = featureElem.getAsJsonObject()
      def objectID = id++
      feature.getAsJsonObject("properties").addProperty("OBJECTID", objectID)

      def json = feature.toString()
      def filename = "gkg_geojson_${objectID}.json"
      def entry = new ZipEntry(filename)
      zs.putNextEntry(entry)
      zs.write(json.getBytes())
      zs.closeEntry()
    }

    zs.close()
    fs.close()

    copy {
      from tempFile
      into file("data/gkg_geojson")
      rename { "gkg_geojson.zip" }
    }
    delete tempFile

    println "Downloaded ${(id - startObjectID)} features."
  }
}

task downloadZipCodeBoundaryExampleData(type: Exec) {
  def startObjectID = 50000;
  def tempCloneDir = ".tmp/zipcodes"
  
  executable "git"
  args "clone", "https://github.com/OpenDataDE/State-zip-code-GeoJSON", tempCloneDir
  
  doLast {
    def id = startObjectID
    def srcFiles = fileTree(tempCloneDir).matching({
      include "*.json"
    })
    for (srcFile in srcFiles) {
      def srcFilename = FilenameUtils.removeExtension(srcFile.getName())
      println "Processing ${srcFile.getName()}..."

      def tempFile = File.createTempFile(srcFilename + "_", ".zip")
      def fs = new FileOutputStream(tempFile)
      def zs = new ZipOutputStream(fs)
      
      def is = srcFile.newInputStream()
      def reader = new JsonReader(new FileReader(srcFile))
      def parser = new JsonParser()

      reader.beginObject()
      assert reader.nextName() == "type"
      assert reader.nextString() == "FeatureCollection"
      assert reader.nextName() == "features"
      reader.beginArray()
      while(reader.hasNext()) { // for every feature
        def featureElem = parser.parse(reader)
        assert featureElem.isJsonObject()
        def feature = featureElem.getAsJsonObject()
        def objectID = id++
        feature.getAsJsonObject("properties").addProperty("OBJECTID", objectID)

        def json = feature.toString()
        def filename = "${srcFilename}_${objectID}.json"
        def entry = new ZipEntry(filename)
        zs.putNextEntry(entry)
        zs.write(json.getBytes())
        zs.closeEntry()
      }
      reader.endArray()
      reader.endObject()
      reader.close()

      is.close()
      zs.close()
      fs.close()

      copy {
        from tempFile
        into file("data/zipcodes")
        rename { "${srcFilename}.zip" }
      }
      delete tempFile
    }
    
    println "Downloaded ${(id - startObjectID)} features."
    delete tempCloneDir
  }
}